{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18e14897-bd7d-40ca-ab65-4ddd2646c0af",
   "metadata": {},
   "source": [
    "# Datetime and Location extraction using Finetuned Encoder Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7578c614-816d-46e8-bbe6-37587b504422",
   "metadata": {},
   "source": [
    "## Install the packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c7ec18b-609b-41df-93cc-9642bae51d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade transformers datasets accelerate\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02078472-f75f-4c93-8cec-9a63946aa1e2",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f352e1-5476-4a1b-8ea3-fa8eef5973fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datasets import Dataset, ClassLabel\n",
    "from transformers import RobertaTokenizerFast\n",
    "from transformers import DataCollatorForTokenClassification\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('../data/encoder-ner.csv', converters={'tokens': eval, 'ner_tags': eval})\n",
    "data = Dataset.from_pandas(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc0cf45-7c0e-4d08-8428-d3d5b52ecde6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Visualize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c87728-8801-4242-89d7-99bbc62cfd02",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad4898c-cd85-46b9-ace4-b25e99986542",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Format the data for finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c762ee4e-5352-4691-9ad2-960f7607ecf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define unique labels\n",
    "unique_labels = ['O', 'DATE', 'LOCATION']  # add all your labels here\n",
    "label_dict = {label: i for i, label in enumerate(unique_labels)}\n",
    "\n",
    "# Update the dataset with encoded labels\n",
    "def encode_labels(examples):\n",
    "    try:\n",
    "        return {'ner_tags': [label_dict[label] for label in examples['ner_tags']]}\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "data = data.map(encode_labels)\n",
    "\n",
    "def convert_list(input_list):\n",
    "    output_list = input_list\n",
    "    for i in range(2, len(output_list) - 1):\n",
    "        if output_list[i - 2] == 1 and output_list[i - 1] == 1 and output_list[i] == 0 and output_list[i + 1] == 1:\n",
    "            output_list[i] = 1\n",
    "            break\n",
    "    return output_list\n",
    "\n",
    "\n",
    "\n",
    "def consolidate_labels(dataset):\n",
    "    dataset[\"ner_tags\"] = convert_list(dataset[\"ner_tags\"])\n",
    "        \n",
    "    return dataset\n",
    "\n",
    "data = data.map(consolidate_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68dfec30-e6bb-4b63-a0ac-5755138a1c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf82ddf-d6ee-43ba-9be7-ba69c56c77de",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load tokenizer\n",
    "tokenizer = RobertaTokenizerFast.from_pretrained('roberta-base', add_prefix_space=True)\n",
    "\n",
    "# Function to tokenize and align labels\n",
    "def tokenize_and_align_labels(examples, label_all_tokens=True):\n",
    "    tokenized_inputs = tokenizer(examples[\"tokens\"], truncation=True, is_split_into_words=True)\n",
    "    labels = []\n",
    "    for i, label in enumerate(examples[\"ner_tags\"]):\n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=i)\n",
    "        print(label, word_ids)\n",
    "        previous_word_idx = None\n",
    "        label_ids = []\n",
    "        for word_idx in word_ids:\n",
    "            try:\n",
    "                if word_idx is None:\n",
    "                    label_ids.append(-100)\n",
    "                elif word_idx != previous_word_idx:\n",
    "                    label_ids.append(label[word_idx])\n",
    "                else:\n",
    "                    label_ids.append(label[word_idx] if label_all_tokens else -100)\n",
    "                previous_word_idx = word_idx  # Update previous_word_idx inside the loop\n",
    "            except Exception as e:  # Use Exception instead of error\n",
    "                continue\n",
    "        labels.append(label_ids)\n",
    "    tokenized_inputs[\"labels\"] = labels\n",
    "    return tokenized_inputs\n",
    "\n",
    "tokenized_datasets = data.map(tokenize_and_align_labels, batched=True, batch_size=128)\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0399160-e78c-4ea1-a121-40d4163c2755",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_datasets[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e687699-538c-4159-ae6c-aca23803801c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create Huggingface Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace9dbb2-2485-431a-8f3c-fc61f24043b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import RobertaForTokenClassification, Trainer, TrainingArguments\n",
    "\n",
    "model = RobertaForTokenClassification.from_pretrained(\n",
    "    'roberta-base',\n",
    "    num_labels=len(unique_labels) # This should match your total number of NER tags\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1781c50d-5d72-4da7-a640-8ee830377cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define Training Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b17512-5dc1-4158-9ea6-4012523df45a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',          # Output directory\n",
    "    evaluation_strategy=\"epoch\",     # Evaluation is done at the end of each epoch\n",
    "    learning_rate=2e-4,\n",
    "    num_train_epochs=10,\n",
    "    weight_decay=0.01,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets,  # Assuming you have a train split\n",
    "    eval_dataset=tokenized_datasets,  # Assuming you have a train split\n",
    "    data_collator = data_collator\n",
    ")\n",
    "\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e2e6ba3-0659-4a76-a153-b21337ee5979",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a429170d-b19b-4d38-8581-ba441dea4399",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained('./finetuned_roberta_ner')\n",
    "tokenizer.save_pretrained('./finetuned_roberta_ner')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "310b5cf6-809c-47a7-8a71-a2c67fe40172",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Test model with examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba939e5e-4cf5-452e-9bd0-0434aad6e94d",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Crop types in Spain durin 23 April, 2023.\"\n",
    "inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=512)\n",
    "print(inputs)\n",
    "for k, v in inputs.items():\n",
    "    print(k, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e09d3b-d18b-42c9-b2c3-4a995a62fe66",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "ner_pipeline = pipeline(\"ner\", model=model, tokenizer=tokenizer)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f0bd33-ffcc-4f45-898f-3cacbca258e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_classes = ner_pipeline(text)\n",
    "print(ner_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c098df6b-3ded-44f9-a523-88b246452609",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Crop types in Spain as of yesterday.\"\n",
    "ner_classes = ner_pipeline(text)\n",
    "print(ner_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4877b1d3-d16c-4228-acbe-b5c6851a4a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d48c11-870d-4ee1-8b76-18e6ccddb21a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Conver NER format to JSON format\n",
    "\n",
    "def ner_to_dict(ner_result):\n",
    "    result = dict()\n",
    "    for item in ner_result:\n",
    "        if item['entity'] in [\"LABEL_1\", \"LABEL_2\"]:\n",
    "            if item['entity'] in result.keys():\n",
    "                result[item['entity']] += item['word']\n",
    "            else:\n",
    "                result[item['entity']] = \"\"\n",
    "                result[item['entity']] += item['word']\n",
    "    old_keys = list(result.keys())\n",
    "    \n",
    "    for key in old_keys:\n",
    "        new_key = unique_labels[int(key[-1])]\n",
    "        result[new_key] = result[key]\n",
    "        del result[key]\n",
    "    \n",
    "    for key, val in result.items():\n",
    "        result[key] = val.replace('Ġ', ' ')[1:]\n",
    "\n",
    "    return result\n",
    "\n",
    "print(ner_to_dict(ner_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0296834-1ac3-44a8-8de4-8ad59462ea3d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "8987afb44532b2110e1a5e1b229dd281f8440b44477d285826a54acdd52d8797"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
